{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Power BI Dashboard Preparation\n",
      "============================================================\n",
      "ðŸš€ POWER BI PREPARATION PIPELINE\n",
      "============================================================\n",
      "ðŸ“… Creating temporal data for dashboard...\n",
      "âœ… Temporal data created from 2024-01-01 00:37:28.921058 to 2024-01-31 23:08:57.777325\n",
      "ðŸŒ Creating geographic data...\n",
      "âœ… Geographic data created for 10 locations\n",
      "ðŸŒ Creating network metadata...\n",
      "âœ… Network metadata created\n",
      "ðŸ“Š Creating KPI data...\n",
      "âœ… KPI data created\n",
      "âš¡ Creating real-time simulation data...\n",
      "âœ… Real-time simulation data created (8479 intervals)\n",
      "ðŸ” Creating threat intelligence data...\n",
      "âœ… Threat intelligence data created\n",
      "ðŸ“¤ Exporting data for Power BI to powerbi_data/...\n",
      "  âœ… Main dataset exported\n",
      "  âœ… KPI summary exported\n",
      "  âœ… Geographic summary exported\n",
      "  âœ… Temporal patterns exported\n",
      "  âœ… Protocol analysis exported\n",
      "  âœ… Threat intelligence exported\n",
      "  âœ… DAX measures exported\n",
      "  âœ… Model performance exported\n",
      "\n",
      "âœ… All data exported to powerbi_data/\n",
      "ðŸ“‹ Files created:\n",
      "  â€¢ network_traffic_data.csv - Main dataset\n",
      "  â€¢ kpi_summary.csv - Key performance indicators\n",
      "  â€¢ geographic_summary.csv - Geographic analysis\n",
      "  â€¢ temporal_patterns.csv - Time-based patterns\n",
      "  â€¢ protocol_analysis.csv - Protocol security analysis\n",
      "  â€¢ threat_intelligence.csv - Threat type analysis\n",
      "  â€¢ model_performance.csv - ML model comparison\n",
      "  â€¢ dax_measures.txt - Power BI DAX formulas\n",
      "\n",
      "ðŸ“Š POWER BI DASHBOARD STRUCTURE GUIDE\n",
      "============================================================\n",
      "ðŸ“‹ DASHBOARD PAGES STRUCTURE:\n",
      "\n",
      "ðŸ”¹ Page 1: Executive Overview\n",
      "   Purpose: High-level KPIs and summary\n",
      "   Key Visuals: Card visuals for Total Traffic, Total Attacks, Attack Rate, Avg Threat Score, Donut chart for Threat Level Distribution, Line chart for Attack Trends over Time...\n",
      "   Interactive Elements: Date Range, Threat Level\n",
      "   Advanced Features: Auto-refresh, Alerts for high threat scores\n",
      "\n",
      "ðŸ”¹ Page 2: Real-Time Monitor\n",
      "   Purpose: Live network monitoring simulation\n",
      "   Key Visuals: Line chart with streaming data simulation, Map visual showing attack origins, Matrix showing recent attacks...\n",
      "   Interactive Elements: Time Window, Protocol, Country\n",
      "   Advanced Features: Auto-refresh every 30 seconds, Bookmarks for incident response\n",
      "\n",
      "ðŸ”¹ Page 3: Threat Intelligence\n",
      "   Purpose: Detailed threat analysis\n",
      "   Key Visuals: Treemap for Attack Types, Scatter plot for Threat Score vs Traffic Volume, Heatmap for Hour vs Day attack patterns...\n",
      "   Interactive Elements: Attack Type, Severity Level, Time Period\n",
      "   Advanced Features: Drill-through to detailed records, Custom tooltips\n",
      "\n",
      "ðŸ”¹ Page 4: Geographic Analysis\n",
      "   Purpose: Geographic threat distribution\n",
      "   Key Visuals: Filled map for global attack distribution, Bar chart for country-wise attack rates, Table with country details...\n",
      "   Interactive Elements: Continent, Threat Level\n",
      "   Advanced Features: Custom map shapes, Geographic drill-down\n",
      "\n",
      "ðŸ”¹ Page 5: ML Model Performance\n",
      "   Purpose: Model evaluation and insights\n",
      "   Key Visuals: Column chart comparing model metrics, Line chart for model performance over time, Key Influencers visual for attack predictors...\n",
      "   Interactive Elements: Model Type, Evaluation Metric\n",
      "   Advanced Features: AI visuals, What-if parameters\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "#Power BI Dashboard Data Preparation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import random\n",
    "from geopy.geocoders import Nominatim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PowerBIDashboardPrep:\n",
    "    \"\"\"\n",
    "    Prepare data specifically for Power BI dashboard visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_with_threats, model_results):\n",
    "        self.df = df_with_threats\n",
    "        self.model_results = model_results\n",
    "        self.dashboard_data = {}\n",
    "        \n",
    "    def create_temporal_data(self, start_date=\"2024-01-01\", days=30):\n",
    "        \"\"\"Create synthetic temporal data for real-time simulation\"\"\"\n",
    "        print(\"ðŸ“… Creating temporal data for dashboard...\")\n",
    "        \n",
    "        # Generate timestamps\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        timestamps = []\n",
    "        \n",
    "        for i in range(len(self.df)):\n",
    "            # Random timestamp within the specified period\n",
    "            random_days = random.uniform(0, days)\n",
    "            random_hours = random.uniform(0, 24)\n",
    "            timestamp = start + timedelta(days=random_days, hours=random_hours)\n",
    "            timestamps.append(timestamp)\n",
    "        \n",
    "        self.df['Timestamp'] = timestamps\n",
    "        self.df['Date'] = pd.to_datetime(self.df['Timestamp']).dt.date\n",
    "        self.df['Hour'] = pd.to_datetime(self.df['Timestamp']).dt.hour\n",
    "        self.df['Day_of_Week'] = pd.to_datetime(self.df['Timestamp']).dt.day_name()\n",
    "        self.df['Week_Number'] = pd.to_datetime(self.df['Timestamp']).dt.isocalendar().week\n",
    "        \n",
    "        print(f\"âœ… Temporal data created from {min(timestamps)} to {max(timestamps)}\")\n",
    "        return self.df\n",
    "    \n",
    "    def create_geographic_data(self):\n",
    "        \"\"\"Create synthetic geographic data for IP mapping\"\"\"\n",
    "        print(\"ðŸŒ Creating geographic data...\")\n",
    "        \n",
    "        # Sample cities and coordinates (in real scenario, use IP geolocation service)\n",
    "        cities_data = [\n",
    "            {\"City\": \"New York\", \"Country\": \"USA\", \"Latitude\": 40.7128, \"Longitude\": -74.0060},\n",
    "            {\"City\": \"London\", \"Country\": \"UK\", \"Latitude\": 51.5074, \"Longitude\": -0.1278},\n",
    "            {\"City\": \"Tokyo\", \"Country\": \"Japan\", \"Latitude\": 35.6762, \"Longitude\": 139.6503},\n",
    "            {\"City\": \"Sydney\", \"Country\": \"Australia\", \"Latitude\": -33.8688, \"Longitude\": 151.2093},\n",
    "            {\"City\": \"Toronto\", \"Country\": \"Canada\", \"Latitude\": 43.6532, \"Longitude\": -79.3832},\n",
    "            {\"City\": \"Berlin\", \"Country\": \"Germany\", \"Latitude\": 52.5200, \"Longitude\": 13.4050},\n",
    "            {\"City\": \"Mumbai\", \"Country\": \"India\", \"Latitude\": 19.0760, \"Longitude\": 72.8777},\n",
    "            {\"City\": \"SÃ£o Paulo\", \"Country\": \"Brazil\", \"Latitude\": -23.5505, \"Longitude\": -46.6333},\n",
    "            {\"City\": \"Moscow\", \"Country\": \"Russia\", \"Latitude\": 55.7558, \"Longitude\": 37.6176},\n",
    "            {\"City\": \"Beijing\", \"Country\": \"China\", \"Latitude\": 39.9042, \"Longitude\": 116.4074}\n",
    "        ]\n",
    "        \n",
    "        # Assign random locations (weighted towards certain regions for attacks)\n",
    "        locations = []\n",
    "        for i in range(len(self.df)):\n",
    "            if self.df.iloc[i]['Actual_Attack'] == 1:\n",
    "                # Attacks more likely from certain regions\n",
    "                weights = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.25, 0.25]\n",
    "            else:\n",
    "                # Normal traffic more evenly distributed\n",
    "                weights = [0.15, 0.15, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05, 0.075, 0.075]\n",
    "            \n",
    "            location = random.choices(cities_data, weights=weights)[0]\n",
    "            locations.append(location)\n",
    "        \n",
    "        # Add geographic columns\n",
    "        geo_df = pd.DataFrame(locations)\n",
    "        self.df['Source_City'] = geo_df['City']\n",
    "        self.df['Source_Country'] = geo_df['Country']\n",
    "        self.df['Source_Latitude'] = geo_df['Latitude']\n",
    "        self.df['Source_Longitude'] = geo_df['Longitude']\n",
    "        \n",
    "        print(f\"âœ… Geographic data created for {len(cities_data)} locations\")\n",
    "        return self.df\n",
    "    \n",
    "    def create_network_metadata(self):\n",
    "        \"\"\"Create network-specific metadata for dashboard\"\"\"\n",
    "        print(\"ðŸŒ Creating network metadata...\")\n",
    "        \n",
    "        # Protocol types\n",
    "        protocols = ['TCP', 'UDP', 'ICMP', 'HTTP', 'HTTPS', 'FTP', 'SSH', 'DNS']\n",
    "        protocol_weights = [0.3, 0.25, 0.1, 0.15, 0.1, 0.03, 0.04, 0.03]\n",
    "        \n",
    "        self.df['Protocol'] = random.choices(protocols, weights=protocol_weights, k=len(self.df))\n",
    "        \n",
    "        # Port numbers (simplified)\n",
    "        common_ports = {\n",
    "            'TCP': [80, 443, 21, 22, 23, 25, 53, 110, 143, 993, 995],\n",
    "            'UDP': [53, 67, 68, 69, 123, 161, 162, 514],\n",
    "            'HTTP': [80, 8080, 8000],\n",
    "            'HTTPS': [443, 8443],\n",
    "            'FTP': [21, 20],\n",
    "            'SSH': [22],\n",
    "            'DNS': [53],\n",
    "            'ICMP': [0]\n",
    "        }\n",
    "        \n",
    "        ports = []\n",
    "        for protocol in self.df['Protocol']:\n",
    "            if protocol in common_ports:\n",
    "                port = random.choice(common_ports[protocol])\n",
    "            else:\n",
    "                port = random.randint(1024, 65535)\n",
    "            ports.append(port)\n",
    "        \n",
    "        self.df['Destination_Port'] = ports\n",
    "        \n",
    "        # Service names\n",
    "        service_mapping = {\n",
    "            80: 'HTTP', 443: 'HTTPS', 21: 'FTP', 22: 'SSH', \n",
    "            23: 'Telnet', 25: 'SMTP', 53: 'DNS', 110: 'POP3'\n",
    "        }\n",
    "        \n",
    "        self.df['Service'] = self.df['Destination_Port'].map(service_mapping).fillna('Other')\n",
    "        \n",
    "        print(\"âœ… Network metadata created\")\n",
    "        return self.df\n",
    "    \n",
    "    def create_kpi_data(self):\n",
    "        \"\"\"Create KPI summary data for dashboard overview\"\"\"\n",
    "        print(\"ðŸ“Š Creating KPI data...\")\n",
    "        \n",
    "        # Overall metrics\n",
    "        total_flows = len(self.df)\n",
    "        total_attacks = self.df['Actual_Attack'].sum()\n",
    "        attack_rate = (total_attacks / total_flows) * 100\n",
    "        avg_threat_score = self.df['Threat_Score'].mean()\n",
    "        \n",
    "        # Threat level distribution\n",
    "        threat_distribution = self.df['Threat_Level'].value_counts().to_dict()\n",
    "        \n",
    "        # Top attack sources\n",
    "        top_attack_countries = self.df[self.df['Actual_Attack'] == 1]['Source_Country'].value_counts().head(5).to_dict()\n",
    "        \n",
    "        # Protocol-wise attack rates\n",
    "        protocol_attacks = self.df.groupby('Protocol').agg({\n",
    "            'Actual_Attack': ['count', 'sum']\n",
    "        }).round(2)\n",
    "        protocol_attacks.columns = ['Total_Flows', 'Attack_Count']\n",
    "        protocol_attacks['Attack_Rate'] = (protocol_attacks['Attack_Count'] / protocol_attacks['Total_Flows'] * 100).round(2)\n",
    "        \n",
    "        # Hourly patterns\n",
    "        hourly_stats = self.df.groupby('Hour').agg({\n",
    "            'Actual_Attack': ['count', 'sum'],\n",
    "            'Threat_Score': 'mean'\n",
    "        }).round(2)\n",
    "        hourly_stats.columns = ['Total_Flows', 'Attack_Count', 'Avg_Threat_Score']\n",
    "        \n",
    "        # Daily patterns\n",
    "        daily_stats = self.df.groupby('Day_of_Week').agg({\n",
    "            'Actual_Attack': ['count', 'sum'],\n",
    "            'Threat_Score': 'mean'\n",
    "        }).round(2)\n",
    "        daily_stats.columns = ['Total_Flows', 'Attack_Count', 'Avg_Threat_Score']\n",
    "        \n",
    "        kpi_data = {\n",
    "            'overview': {\n",
    "                'total_flows': int(total_flows),\n",
    "                'total_attacks': int(total_attacks),\n",
    "                'attack_rate': round(attack_rate, 2),\n",
    "                'avg_threat_score': round(avg_threat_score, 2)\n",
    "            },\n",
    "            'threat_distribution': threat_distribution,\n",
    "            'top_attack_countries': top_attack_countries,\n",
    "            'protocol_stats': protocol_attacks.to_dict('index'),\n",
    "            'hourly_patterns': hourly_stats.to_dict('index'),\n",
    "            'daily_patterns': daily_stats.to_dict('index')\n",
    "        }\n",
    "        \n",
    "        self.dashboard_data['kpis'] = kpi_data\n",
    "        \n",
    "        print(\"âœ… KPI data created\")\n",
    "        return kpi_data\n",
    "    \n",
    "    def create_real_time_simulation_data(self):\n",
    "        \"\"\"Create data structure for real-time dashboard simulation\"\"\"\n",
    "        print(\"âš¡ Creating real-time simulation data...\")\n",
    "        \n",
    "        # Sort by timestamp for streaming simulation\n",
    "        df_sorted = self.df.sort_values('Timestamp').copy()\n",
    "        \n",
    "        # Create 5-minute intervals for streaming\n",
    "        df_sorted['Time_Interval'] = pd.to_datetime(df_sorted['Timestamp']).dt.floor('5T')\n",
    "        \n",
    "        # Aggregate by intervals\n",
    "        interval_stats = df_sorted.groupby('Time_Interval').agg({\n",
    "            'Actual_Attack': ['count', 'sum'],\n",
    "            'Threat_Score': ['mean', 'max'],\n",
    "            'Source_Country': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown',\n",
    "            'Protocol': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown'\n",
    "        }).round(2)\n",
    "        \n",
    "        interval_stats.columns = ['Flow_Count', 'Attack_Count', 'Avg_Threat_Score', 'Max_Threat_Score', 'Top_Country', 'Top_Protocol']\n",
    "        interval_stats['Attack_Rate'] = (interval_stats['Attack_Count'] / interval_stats['Flow_Count'] * 100).round(2)\n",
    "        \n",
    "        # Reset index to make timestamp a column\n",
    "        interval_stats = interval_stats.reset_index()\n",
    "        \n",
    "        self.dashboard_data['real_time'] = interval_stats\n",
    "        \n",
    "        print(f\"âœ… Real-time simulation data created ({len(interval_stats)} intervals)\")\n",
    "        return interval_stats\n",
    "    \n",
    "    def create_threat_intelligence_data(self):\n",
    "        \"\"\"Create threat intelligence summary for dashboard\"\"\"\n",
    "        print(\"ðŸ” Creating threat intelligence data...\")\n",
    "        \n",
    "        # Attack type analysis (based on actual labels if available)\n",
    "        if 'Label' in self.df.columns:\n",
    "            attack_types = self.df[self.df['Actual_Attack'] == 1]['Label'].value_counts().head(10)\n",
    "        else:\n",
    "            # Create synthetic attack types based on threat scores\n",
    "            synthetic_attacks = []\n",
    "            for _, row in self.df[self.df['Actual_Attack'] == 1].iterrows():\n",
    "                if row['Threat_Score'] > 80:\n",
    "                    attack_type = random.choice(['DDoS', 'Brute Force', 'Infiltration'])\n",
    "                elif row['Threat_Score'] > 60:\n",
    "                    attack_type = random.choice(['Port Scan', 'Web Attack', 'Botnet'])\n",
    "                else:\n",
    "                    attack_type = random.choice(['DoS', 'Heartbleed', 'SQL Injection'])\n",
    "                synthetic_attacks.append(attack_type)\n",
    "            \n",
    "            attack_types = pd.Series(synthetic_attacks).value_counts()\n",
    "        \n",
    "        # Severity classification\n",
    "        severity_mapping = {\n",
    "            'DDoS': 'Critical',\n",
    "            'Infiltration': 'Critical',\n",
    "            'Brute Force': 'High',\n",
    "            'Botnet': 'High',\n",
    "            'Web Attack': 'Medium',\n",
    "            'Port Scan': 'Medium',\n",
    "            'DoS': 'Medium',\n",
    "            'Heartbleed': 'High',\n",
    "            'SQL Injection': 'High'\n",
    "        }\n",
    "        \n",
    "        # Create threat intelligence summary\n",
    "        threat_intel = {}\n",
    "        for attack_type, count in attack_types.items():\n",
    "            threat_intel[attack_type] = {\n",
    "                'count': int(count),\n",
    "                'severity': severity_mapping.get(attack_type, 'Medium'),\n",
    "                'percentage': round((count / len(self.df[self.df['Actual_Attack'] == 1])) * 100, 2)\n",
    "            }\n",
    "        \n",
    "        self.dashboard_data['threat_intelligence'] = threat_intel\n",
    "        \n",
    "        print(\"âœ… Threat intelligence data created\")\n",
    "        return threat_intel\n",
    "    \n",
    "    def export_for_powerbi(self, output_dir=\"powerbi_data/\"):\n",
    "        \"\"\"Export all data in Power BI friendly formats\"\"\"\n",
    "        print(f\"ðŸ“¤ Exporting data for Power BI to {output_dir}...\")\n",
    "        \n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Main dataset\n",
    "        main_data = self.df[[\n",
    "            'Timestamp', 'Date', 'Hour', 'Day_of_Week',\n",
    "            'Source_City', 'Source_Country', 'Source_Latitude', 'Source_Longitude',\n",
    "            'Protocol', 'Destination_Port', 'Service',\n",
    "            'Threat_Score', 'Threat_Level', 'Actual_Attack'\n",
    "        ]].copy()\n",
    "        \n",
    "        main_data.to_csv(f\"{output_dir}network_traffic_data.csv\", index=False)\n",
    "        print(\"  âœ… Main dataset exported\")\n",
    "        \n",
    "        # 2. KPI summary\n",
    "        kpi_summary = pd.DataFrame([self.dashboard_data['kpis']['overview']])\n",
    "        kpi_summary.to_csv(f\"{output_dir}kpi_summary.csv\", index=False)\n",
    "        print(\"  âœ… KPI summary exported\")\n",
    "        \n",
    "        # 3. Geographic summary\n",
    "        geo_summary = self.df.groupby(['Source_Country', 'Source_City', 'Source_Latitude', 'Source_Longitude']).agg({\n",
    "            'Actual_Attack': ['count', 'sum'],\n",
    "            'Threat_Score': 'mean'\n",
    "        }).round(2)\n",
    "        geo_summary.columns = ['Total_Flows', 'Attack_Count', 'Avg_Threat_Score']\n",
    "        geo_summary['Attack_Rate'] = (geo_summary['Attack_Count'] / geo_summary['Total_Flows'] * 100).round(2)\n",
    "        geo_summary = geo_summary.reset_index()\n",
    "        geo_summary.to_csv(f\"{output_dir}geographic_summary.csv\", index=False)\n",
    "        print(\"  âœ… Geographic summary exported\")\n",
    "        \n",
    "        # 4. Temporal patterns\n",
    "        temporal_summary = self.dashboard_data['real_time']\n",
    "        temporal_summary.to_csv(f\"{output_dir}temporal_patterns.csv\", index=False)\n",
    "        print(\"  âœ… Temporal patterns exported\")\n",
    "        \n",
    "        # 5. Protocol analysis\n",
    "        protocol_summary = pd.DataFrame.from_dict(self.dashboard_data['kpis']['protocol_stats'], orient='index')\n",
    "        protocol_summary = protocol_summary.reset_index()\n",
    "        protocol_summary.rename(columns={'index': 'Protocol'}, inplace=True)\n",
    "        protocol_summary.to_csv(f\"{output_dir}protocol_analysis.csv\", index=False)\n",
    "        print(\"  âœ… Protocol analysis exported\")\n",
    "        \n",
    "        # 6. Threat intelligence\n",
    "        threat_intel_df = pd.DataFrame.from_dict(self.dashboard_data['threat_intelligence'], orient='index')\n",
    "        threat_intel_df = threat_intel_df.reset_index()\n",
    "        threat_intel_df.rename(columns={'index': 'Attack_Type'}, inplace=True)\n",
    "        threat_intel_df.to_csv(f\"{output_dir}threat_intelligence.csv\", index=False)\n",
    "        print(\"  âœ… Threat intelligence exported\")\n",
    "        \n",
    "        # 7. Create DAX measures file (text file with DAX formulas)\n",
    "        dax_measures = \"\"\"\n",
    "-- Key Performance Indicators\n",
    "Total Traffic = COUNTROWS('network_traffic_data')\n",
    "\n",
    "Total Attacks = SUMX('network_traffic_data', 'network_traffic_data'[Actual_Attack])\n",
    "\n",
    "Attack Rate = DIVIDE([Total Attacks], [Total Traffic], 0) * 100\n",
    "\n",
    "Average Threat Score = AVERAGE('network_traffic_data'[Threat_Score])\n",
    "\n",
    "-- Time Intelligence\n",
    "Current Hour Attacks = \n",
    "CALCULATE(\n",
    "    [Total Attacks],\n",
    "    FILTER(\n",
    "        'network_traffic_data',\n",
    "        'network_traffic_data'[Hour] = HOUR(NOW())\n",
    "    )\n",
    ")\n",
    "\n",
    "Previous Hour Attacks = \n",
    "CALCULATE(\n",
    "    [Total Attacks],\n",
    "    FILTER(\n",
    "        'network_traffic_data',\n",
    "        'network_traffic_data'[Hour] = HOUR(NOW()) - 1\n",
    "    )\n",
    ")\n",
    "\n",
    "Attack Trend = [Current Hour Attacks] - [Previous Hour Attacks]\n",
    "\n",
    "-- Top Attackers (Dynamic)\n",
    "Top Attack Country = \n",
    "TOPN(\n",
    "    1,\n",
    "    SUMMARIZE(\n",
    "        FILTER('network_traffic_data', 'network_traffic_data'[Actual_Attack] = 1),\n",
    "        'network_traffic_data'[Source_Country],\n",
    "        \"Attack Count\", [Total Attacks]\n",
    "    ),\n",
    "    [Attack Count],\n",
    "    DESC\n",
    ")\n",
    "\n",
    "-- Threat Level Analysis\n",
    "Critical Threats = \n",
    "CALCULATE(\n",
    "    [Total Traffic],\n",
    "    'network_traffic_data'[Threat_Level] = \"Critical\"\n",
    ")\n",
    "\n",
    "High Threats = \n",
    "CALCULATE(\n",
    "    [Total Traffic],\n",
    "    'network_traffic_data'[Threat_Level] = \"High\"\n",
    ")\n",
    "\n",
    "Threat Level Distribution = \n",
    "CONCATENATEX(\n",
    "    SUMMARIZE(\n",
    "        'network_traffic_data',\n",
    "        'network_traffic_data'[Threat_Level],\n",
    "        \"Count\", [Total Traffic]\n",
    "    ),\n",
    "    'network_traffic_data'[Threat_Level] & \": \" & [Count],\n",
    "    \", \"\n",
    ")\n",
    "\n",
    "-- Advanced Analytics\n",
    "Rolling Average Threat Score = \n",
    "AVERAGEX(\n",
    "    DATESINPERIOD(\n",
    "        'network_traffic_data'[Date],\n",
    "        LASTDATE('network_traffic_data'[Date]),\n",
    "        -7,\n",
    "        DAY\n",
    "    ),\n",
    "    [Average Threat Score]\n",
    ")\n",
    "\n",
    "Anomaly Score = \n",
    "IF(\n",
    "    [Average Threat Score] > [Rolling Average Threat Score] * 1.5,\n",
    "    \"High Anomaly\",\n",
    "    IF(\n",
    "        [Average Threat Score] > [Rolling Average Threat Score] * 1.2,\n",
    "        \"Medium Anomaly\",\n",
    "        \"Normal\"\n",
    "    )\n",
    ")\n",
    "\n",
    "-- Geographic Analysis\n",
    "Attack Density = \n",
    "DIVIDE(\n",
    "    [Total Attacks],\n",
    "    CALCULATE([Total Traffic], ALL('network_traffic_data'[Source_Country])),\n",
    "    0\n",
    ") * 100\n",
    "\n",
    "-- Protocol Security Analysis\n",
    "Protocol Risk Score = \n",
    "SWITCH(\n",
    "    SELECTEDVALUE('network_traffic_data'[Protocol]),\n",
    "    \"TCP\", [Attack Rate] * 1.2,\n",
    "    \"UDP\", [Attack Rate] * 1.1,\n",
    "    \"ICMP\", [Attack Rate] * 1.5,\n",
    "    \"HTTP\", [Attack Rate] * 1.3,\n",
    "    \"HTTPS\", [Attack Rate] * 0.8,\n",
    "    [Attack Rate]\n",
    ")\n",
    "\"\"\"\n",
    "        \n",
    "        with open(f\"{output_dir}dax_measures.txt\", \"w\") as f:\n",
    "            f.write(dax_measures)\n",
    "        print(\"  âœ… DAX measures exported\")\n",
    "        \n",
    "        # 8. Export model performance data\n",
    "        if hasattr(self, 'model_results'):\n",
    "            model_performance = []\n",
    "            for model_name, results in self.model_results.items():\n",
    "                if 'test_predictions' in results:\n",
    "                    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "                    \n",
    "                    y_true = self.df['Actual_Attack']  # Assuming this exists\n",
    "                    y_pred = results['test_predictions']\n",
    "                    \n",
    "                    if len(y_true) == len(y_pred):\n",
    "                        model_performance.append({\n",
    "                            'Model': model_name,\n",
    "                            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "                            'Precision': precision_score(y_true, y_pred),\n",
    "                            'Recall': recall_score(y_true, y_pred),\n",
    "                            'F1_Score': f1_score(y_true, y_pred)\n",
    "                        })\n",
    "            \n",
    "            if model_performance:\n",
    "                model_df = pd.DataFrame(model_performance)\n",
    "                model_df.to_csv(f\"{output_dir}model_performance.csv\", index=False)\n",
    "                print(\"  âœ… Model performance exported\")\n",
    "        \n",
    "        print(f\"\\nâœ… All data exported to {output_dir}\")\n",
    "        print(\"ðŸ“‹ Files created:\")\n",
    "        files = [\n",
    "            \"network_traffic_data.csv - Main dataset\",\n",
    "            \"kpi_summary.csv - Key performance indicators\", \n",
    "            \"geographic_summary.csv - Geographic analysis\",\n",
    "            \"temporal_patterns.csv - Time-based patterns\",\n",
    "            \"protocol_analysis.csv - Protocol security analysis\",\n",
    "            \"threat_intelligence.csv - Threat type analysis\",\n",
    "            \"model_performance.csv - ML model comparison\",\n",
    "            \"dax_measures.txt - Power BI DAX formulas\"\n",
    "        ]\n",
    "        \n",
    "        for file in files:\n",
    "            print(f\"  â€¢ {file}\")\n",
    "    \n",
    "    def create_dashboard_structure_guide(self):\n",
    "        \"\"\"Create a guide for Power BI dashboard structure\"\"\"\n",
    "        print(\"\\nðŸ“Š POWER BI DASHBOARD STRUCTURE GUIDE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        dashboard_structure = {\n",
    "            \"Page 1: Executive Overview\": {\n",
    "                \"purpose\": \"High-level KPIs and summary\",\n",
    "                \"visuals\": [\n",
    "                    \"Card visuals for Total Traffic, Total Attacks, Attack Rate, Avg Threat Score\",\n",
    "                    \"Donut chart for Threat Level Distribution\", \n",
    "                    \"Line chart for Attack Trends over Time\",\n",
    "                    \"Bar chart for Top Attack Countries\",\n",
    "                    \"Gauge for Real-time Threat Score\"\n",
    "                ],\n",
    "                \"slicers\": [\"Date Range\", \"Threat Level\"],\n",
    "                \"features\": [\"Auto-refresh\", \"Alerts for high threat scores\"]\n",
    "            },\n",
    "            \n",
    "            \"Page 2: Real-Time Monitor\": {\n",
    "                \"purpose\": \"Live network monitoring simulation\",\n",
    "                \"visuals\": [\n",
    "                    \"Line chart with streaming data simulation\",\n",
    "                    \"Map visual showing attack origins\", \n",
    "                    \"Matrix showing recent attacks\",\n",
    "                    \"Funnel chart for attack severity pipeline\"\n",
    "                ],\n",
    "                \"slicers\": [\"Time Window\", \"Protocol\", \"Country\"],\n",
    "                \"features\": [\"Auto-refresh every 30 seconds\", \"Bookmarks for incident response\"]\n",
    "            },\n",
    "            \n",
    "            \"Page 3: Threat Intelligence\": {\n",
    "                \"purpose\": \"Detailed threat analysis\",\n",
    "                \"visuals\": [\n",
    "                    \"Treemap for Attack Types\",\n",
    "                    \"Scatter plot for Threat Score vs Traffic Volume\",\n",
    "                    \"Heatmap for Hour vs Day attack patterns\",\n",
    "                    \"Waterfall chart for threat progression\"\n",
    "                ],\n",
    "                \"slicers\": [\"Attack Type\", \"Severity Level\", \"Time Period\"],\n",
    "                \"features\": [\"Drill-through to detailed records\", \"Custom tooltips\"]\n",
    "            },\n",
    "            \n",
    "            \"Page 4: Geographic Analysis\": {\n",
    "                \"purpose\": \"Geographic threat distribution\",\n",
    "                \"visuals\": [\n",
    "                    \"Filled map for global attack distribution\",\n",
    "                    \"Bar chart for country-wise attack rates\",\n",
    "                    \"Table with country details\",\n",
    "                    \"Flow map showing attack vectors\"\n",
    "                ],\n",
    "                \"slicers\": [\"Continent\", \"Threat Level\"],\n",
    "                \"features\": [\"Custom map shapes\", \"Geographic drill-down\"]\n",
    "            },\n",
    "            \n",
    "            \"Page 5: ML Model Performance\": {\n",
    "                \"purpose\": \"Model evaluation and insights\",\n",
    "                \"visuals\": [\n",
    "                    \"Column chart comparing model metrics\",\n",
    "                    \"Line chart for model performance over time\",\n",
    "                    \"Key Influencers visual for attack predictors\",\n",
    "                    \"Decomposition tree for threat factors\"\n",
    "                ],\n",
    "                \"slicers\": [\"Model Type\", \"Evaluation Metric\"],\n",
    "                \"features\": [\"AI visuals\", \"What-if parameters\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"ðŸ“‹ DASHBOARD PAGES STRUCTURE:\")\n",
    "        for page, details in dashboard_structure.items():\n",
    "            print(f\"\\nðŸ”¹ {page}\")\n",
    "            print(f\"   Purpose: {details['purpose']}\")\n",
    "            print(f\"   Key Visuals: {', '.join(details['visuals'][:3])}...\")\n",
    "            print(f\"   Interactive Elements: {', '.join(details['slicers'])}\")\n",
    "            print(f\"   Advanced Features: {', '.join(details['features'])}\")\n",
    "        \n",
    "        return dashboard_structure\n",
    "    \n",
    "    def run_complete_powerbi_prep(self):\n",
    "        \"\"\"Run complete Power BI preparation pipeline\"\"\"\n",
    "        print(\"ðŸš€ POWER BI PREPARATION PIPELINE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Create temporal data\n",
    "        self.create_temporal_data()\n",
    "        \n",
    "        # Step 2: Create geographic data  \n",
    "        self.create_geographic_data()\n",
    "        \n",
    "        # Step 3: Create network metadata\n",
    "        self.create_network_metadata()\n",
    "        \n",
    "        # Step 4: Create KPI data\n",
    "        self.create_kpi_data()\n",
    "        \n",
    "        # Step 5: Create real-time simulation data\n",
    "        self.create_real_time_simulation_data()\n",
    "        \n",
    "        # Step 6: Create threat intelligence\n",
    "        self.create_threat_intelligence_data()\n",
    "        \n",
    "        # Step 7: Export all data\n",
    "        self.export_for_powerbi()\n",
    "        \n",
    "        # Step 8: Create dashboard guide\n",
    "        self.create_dashboard_structure_guide()\n",
    "        \n",
    "        \n",
    "        return True\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for Power BI preparation\"\"\"\n",
    "    print(\"ðŸ“Š Power BI Dashboard Preparation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    \n",
    "    # Load data \n",
    "    df_with_threats = pd.read_csv('test_data_with_threats.csv')\n",
    "    \n",
    "    # Load model results \n",
    "    import joblib\n",
    "    model_results = joblib.load('models/model_results.pkl')\n",
    "    \n",
    "    # Initialize Power BI prep\n",
    "    powerbi_prep = PowerBIDashboardPrep(df_with_threats, model_results)\n",
    "    \n",
    "    # Run complete preparation\n",
    "    success = powerbi_prep.run_complete_powerbi_prep()\n",
    "    \n",
    "    if success:\n",
    "        print(\"...\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
